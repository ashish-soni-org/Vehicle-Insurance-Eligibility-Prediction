import sys
import pandas as pd
import numpy as np

from src.logger import logging
from src.exception import CustomException
from src.entity.estimator import ModelWrapper
from src.cloud_storage.aws_storage import SimpleStorageService

class CloudModelWrapper:
    """
    Acts as an interface between the ML model stored in S3 and the local pipeline.
    
    This class:
        - Checks if the model exists in S3
        - Loads the model from S3
        - Uploads a new model to S3
        - Performs predictions using the loaded model

    It wraps S3 operations and ensures consistent model handling across training,
    evaluation, and production inference workflows.
    """

    def __init__(self, bucket_name: str, model_path: str):
        """
        Initialize the estimator with S3 bucket details.

        Args:
            bucket_name (str):
                Name of the S3 bucket where the model is stored.
            model_path (str):
                Full S3 key (path) where the model is saved.

        Attributes:
            s3 (SimpleStorageService): S3 helper class for file operations.
            loaded_model (MyModel or None): Cached model instance once loaded.
        """
        self.bucket_name = bucket_name
        self.s3 = SimpleStorageService()
        self.model_path = model_path
        self.load_model: ModelWrapper = None

    def is_model_present(self, model_path: str) -> bool:
        """
        Check whether a model file exists in the specified S3 bucket.

        Args:
            model_path (str):
                S3 key of the model file.

        Returns:
            bool: True if model exists; False otherwise.
        """
        try:
            return self.s3.s3_key_path_available(self.bucket_name, model_path)
        except Exception as e:
            raise CustomException(e, sys) from e

    def save_model(self, from_file: str, remove: bool = False) -> None:
        """
        Upload a trained model file to S3.

        Args:
            from_file (str):
                Local filesystem path of the model file to upload.
            remove (bool, optional):
                If True, delete the local file after uploading.
                Defaults to False.
        """
        try:
             self.s3.upload_file(
                 from_file,
                 self.model_path,
                 self.bucket_name,
                 remove
             )
        except Exception as e:
            raise CustomException(e, sys) from e

    def load_model(self) -> ModelWrapper:
        """
        Load the trained model from S3.

        Returns:
            ModelWrapper: (NOT CloudModelWrapper !!)
                The loaded ML model containing both the preprocessing pipeline
                and the trained estimator.
        """
        try:
            return self.s3.load_model(self.model_path, self.bucket_name)
        except Exception as e:
            raise CustomException(e, sys) from e

    def predict(self, dataframe: pd.DataFrame) -> np.array:
        """
        Perform inference using the loaded model.

        Steps:
            1. Load model from S3 if not already loaded.
            2. Apply preprocessing and prediction on the input DataFrame.

        Args:
            dataframe (DataFrame):
                Input features in raw DataFrame format (before preprocessing).

        Returns:
            numpy.ndarray:
                Predictions generated by the trained model.
        """
        try:
            if self.loaded_model is None:
                self.loaded_model = self.load_model()
            return self.loaded_model.predict(dataframe)
        except Exception as e:
            raise CustomException(e, sys) from e