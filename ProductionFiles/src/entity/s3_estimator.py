import sys
import pandas as pd
import numpy as np

from src.exception import CustomException
from src.entity.estimator import ModelWrapper
from src.cloud_storage.aws_storage import SimpleStorageService

class CloudModelWrapper:
    """
    Acts as an interface between the ML model stored in S3 and the local pipeline.
    
    This class handles the lifecycle of the model artifact in the cloud:
        - Validating model existence in S3
        - Loading the model into memory (using IAM Role credentials implicitly)
        - Uploading new model artifacts
        - Serving predictions via the cached model instance

    It ensures consistent model handling across training, evaluation, 
    and production inference workflows.
    """

    def __init__(self, bucket_name: str, model_path: str):
        """
        Initialize the wrapper with specific S3 bucket and model path details.

        Args:
            bucket_name (str): 
                Name of the S3 bucket where the model is stored.
            model_path (str): 
                Full S3 key (path) where the model is saved (e.g., 'models/model.pkl').

        Attributes:
            s3 (SimpleStorageService): 
                Helper instance for S3 operations. Authentication is handled 
                via the EC2 Instance Profile (IAM Role).
            loaded_model (ModelWrapper | None): 
                Cached model instance in memory.
        """
        self.bucket_name = bucket_name
        self.s3 = SimpleStorageService()
        self.model_path = model_path
        self.loaded_model: ModelWrapper = None

    def is_model_present(self, model_path: str = None) -> bool:
        """
        Check whether the model file exists in the specified S3 bucket.

        Args:
            model_path (str, optional): 
                Specific S3 key to check. If None, uses the instance's configured model_path.

        Returns:
            bool: True if the model object exists in S3; False otherwise.
        """
        try:
            path_to_check = model_path if model_path else self.model_path
            return self.s3.s3_key_path_available(bucket_name=self.bucket_name, key_path=path_to_check)
        except Exception as e:
            raise CustomException(e, sys) from e

    def save_model(self, from_file: str, remove: bool = False) -> None:
        """
        Upload a trained model file from the local filesystem to S3.

        Args:
            from_file (str): 
                Local filesystem path of the model file to upload.
            remove (bool, optional): 
                If True, delete the local file after a successful upload. 
                Defaults to False.
        """
        try:
            self.s3.upload_file(
                from_filename=from_file,
                to_filename=self.model_path,
                bucket_name=self.bucket_name,
                remove=remove
            )
        except Exception as e:
            raise CustomException(e, sys) from e

    def load_model(self) -> ModelWrapper:
        """
        Download and deserialize the trained model from S3 into memory.

        Returns:
            ModelWrapper: 
                The loaded ML model object containing the preprocessing pipeline 
                and the trained estimator.
        """
        try:
            return self.s3.load_model(self.model_path, self.bucket_name)
        except Exception as e:
            raise CustomException(e, sys) from e

    def predict(self, dataframe: pd.DataFrame) -> np.ndarray:
        """
        Perform inference using the loaded model.

        Steps:
            1. Checks if the model is currently cached in `self.loaded_model`.
            2. If not, loads the model from S3.
            3. Applies preprocessing and prediction on the input DataFrame.

        Args:
            dataframe (pd.DataFrame): 
                Input features in raw DataFrame format.

        Returns:
            np.ndarray: 
                Array of predictions generated by the model.
        """
        try:
            if self.loaded_model is None:
                self.loaded_model = self.load_model()
            
            return self.loaded_model.predict(dataframe=dataframe)
        except Exception as e:
            raise CustomException(e, sys) from e  